{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\logoitam.gif\">\n",
    "### Maestría en Ciencia de Datos\n",
    "* Métodos analíticos para texto | Tarea 03 | 11 de febrero de 2016 |\n",
    "* Alumna: Gabriela Flores Bracamontes |  Clave: 160124 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Oculto de Markov - Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Exploración de datos: \n",
    "Una vez explorados los datos, se procedió a realizar la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json_object = json.loads(myjson)\n",
    "    except ValueError, e:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "corpus=\"\"\n",
    "#Limpiamos el archivo\n",
    "j=0\n",
    "with open('corpus_entrenamiento.txt',\"r\") as f:\n",
    "    for line in f: \n",
    "        j+=1\n",
    "        line = line.replace(\",}\", \"}\")\n",
    "        line = line.replace(\"\\\"\\\"document\\\":[\\\"\",\"fc\")\n",
    "        line = line.replace('\\\\\"\"','\\\\\\\\')\n",
    "        line = line.replace (\"\\\"token\\\":\\\"\\\"\\\\\"\"\\\"\\\"\",\"\\\"token\\\":\\\"\"\"\\\\\"\"\\\"\")\n",
    "        line=  line.replace(\"\\\"token\\\":fc\",\"\\\"token\\\":\\\"fc\\\"\")   \n",
    "        line = line.replace(\"}],\",\"}]\")\n",
    "        line=  line.replace('\\n','')\n",
    "        line=  line.replace('}]','}]}\\n')\n",
    "        line=  line.replace('\\\"document\\\":','{\\\"document\\\":')\n",
    "        corpus+= line\n",
    "\n",
    "corpus= corpus[0:len(corpus)-2]\n",
    "\n",
    "with open('corpus_clean.json', 'w') as f:\n",
    "    f.write(corpus)\n",
    "\n",
    "data = []\n",
    "with codecs.open('corpus_clean.json','r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Obtención de los tokens y tags utilizando diccionarios: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DictionaryTokens = {}\n",
    "DictionaryTags = {}\n",
    "\n",
    "for renglon in data:\n",
    "    for contenido in renglon['document']:\n",
    "        DictionaryTokens.setdefault(contenido['token'].lower(),[]) \n",
    "        DictionaryTokens[contenido['token'].lower()].append(contenido['tag'].lower())\n",
    "        DictionaryTags.setdefault(contenido['tag'].lower(),[]) \n",
    "        DictionaryTags[contenido['tag'].lower()].append(contenido['token'].lower())\n",
    "\n",
    "diccionariox = {}\n",
    "for k,v in DictionaryTokens.items():\n",
    "    if not diccionariox.has_key(k) :\n",
    "        diccionariox[k]= Counter(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Generación de la matriz B: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Smoothing de Lindstone\n",
    "def pr (x, cond, N, l=1):\n",
    "\treturn (x+l) / (cond + l*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B= [[0L for j in range(len(DictionaryTags))]for i in range(len(DictionaryTokens))]\n",
    "DictionaryTokensSort= sorted(DictionaryTokens.keys())\n",
    "DictionaryTagsSort= sorted(DictionaryTags.keys())\n",
    "\n",
    "for k,v in diccionariox.items():\n",
    "    idxToken = DictionaryTokensSort.index(k) \n",
    "    for elemento in v.keys():\n",
    "        idxTag = DictionaryTagsSort.index(elemento)\n",
    "        B[idxToken][idxTag]=v[elemento]*1.0\n",
    "        #print B[idxToken][idxTag]\n",
    "B=np.asarray(B)\n",
    "\n",
    "#Matriz de observaciones aplicando smoothing\n",
    "for tk in range(len(DictionaryTokens)):\n",
    "    for tg in range(len(DictionaryTags)):\n",
    "        #print len(DictionaryTokens[DictionaryTokensSort[tk]])\n",
    "        B[tk,tg] = pr(B[(tk,tg)],len(DictionaryTokens[DictionaryTokensSort[tk]]),len(DictionaryTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.075,  0.025,  0.025])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[DictionaryTokensSort.index('hablar')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Generación de la matriz A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A= [[0L for j in range(len(DictionaryTags))]for i in range(len(DictionaryTags))]\n",
    "ATags=[0L for j in range(len(DictionaryTags))]\n",
    "#print A[23]\n",
    "for renglon in data: \n",
    "    document=renglon['document']\n",
    "    De= document[0]['tag'].lower()\n",
    "    DeIdx = DictionaryTagsSort.index(De)\n",
    "    for pos in xrange(1,len(renglon['document'])):  \n",
    "        #print pos\n",
    "        To = document[pos]['tag'].lower()\n",
    "        ToIdx = DictionaryTagsSort.index(To)\n",
    "        #print '%s %s %s' % (De, A[DeIdx][ToIdx], To)\n",
    "        if A[DeIdx][ToIdx]==0 :\n",
    "            ATags[DictionaryTagsSort.index(De)]+=1.0\n",
    "            #print '%s %s %s' % (De, A[DeIdx][ToIdx], To)\n",
    "        A[DeIdx][ToIdx]+=1.0\n",
    "        #print De, To\n",
    "        #print DictionaryTagsSort.index(De)\n",
    "        De = To\n",
    "        DeIdx = DictionaryTagsSort.index(De)\n",
    "    #break\n",
    "A=np.asarray(A)\n",
    "ATags=np.asarray(ATags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Aplicando la función de smoothing\n",
    "for i in range(len(DictionaryTags)):\n",
    "    for j in range(len(DictionaryTags)):\n",
    "        A[i][j]=pr(A[i][j], len(DictionaryTags[DictionaryTagsSort[i]]), ATags[DictionaryTagsSort.index(DictionaryTagsSort[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Generación del vector PI: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PI =[0L for i in range(len(DictionaryTags))]\n",
    "for renglon in data: \n",
    "    document=renglon['document']\n",
    "    De= document[0]['tag'].lower()\n",
    "    PI[DictionaryTagsSort.index(De)]+=1.0\n",
    "PI= np.asarray(PI)\n",
    "\n",
    "#Probabilidades iniciales aplicando smoothing\n",
    "for i in range(len(PI)):\n",
    "    PI[i]= pr(PI[i],len(data),len(PI))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Viterbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el buda fue un sabio\n",
      "[u'da', u'np', u'vs', u'di', u'nc']\n"
     ]
    }
   ],
   "source": [
    "def viterbi(CorpusEvaluacion, Estados, Emisiones, Pi):\n",
    "    CorpusEvaluacion= unicode(CorpusEvaluacion.lower(),\"utf-8\")\n",
    "    print CorpusEvaluacion\n",
    "    observaciones = CorpusEvaluacion.split()\n",
    "    d=[]\n",
    "    phi=[]\n",
    "    delta=[]\n",
    "    for obs in range(len(observaciones)):\n",
    "        if obs==0: # Probabilidad inicial\n",
    "            d=[(Pi[DictionaryTagsSort.index(etiqueta)] * Emisiones[DictionaryTagsSort.index(etiqueta)][DictionaryTokensSort.index(observaciones[obs])]) \n",
    "               for valor,etiqueta in enumerate(DictionaryTagsSort)] #Pi * Emisiones\n",
    "            phi.append(DictionaryTagsSort[d.index(max(d))])#Guardo el id del valor máximo\n",
    "            delta.append(max(d))#Guardo el valor máximo\n",
    "        else:\n",
    "            d=[] #phi(t+1)= Max Arg delta[t]*Estados(t|t-1)*Emisones(t|w)\n",
    "            d= [delta[obs-1]*Estados[y0][DictionaryTagsSort.index(phi[obs-1])]*Emisiones[y0][DictionaryTokensSort.index(observaciones[obs])] \n",
    "               for y0,values in enumerate(DictionaryTagsSort)]\n",
    "            phi.append(DictionaryTagsSort[d.index(max(d))])\n",
    "            delta.append(max(d))\n",
    "    return phi\n",
    "\n",
    "print viterbi(\"El Buda fue un sabio\", np.array(np.matrix(A).transpose()), np.array(np.matrix(B).transpose()), np.array(np.matrix(PI).transpose()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
